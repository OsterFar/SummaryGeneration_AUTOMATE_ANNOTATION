,Reference Article,Citation Marker,Citance Number,Citing Article,Citation Marker Offset,Citation Offset,Citation Text,Reference Offset,Reference Textt,Discourse Facet
0,P04-1036,"McCarthy et al, 2004",1,W04-0837,0,0,"The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding con text into account (McCarthy et al, 2004)","[8, 48, 14]","['The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.', 'To find the first sense of a word ( ) we take each sense in turn and obtain a score reflecting the prevalence which is used for ranking.', 'Even systems which show superior performance to this heuristic often make use of the heuristic where evidence from the context is not sufficient (Hoste et al., 2001).']",Method_Citation
1,P04-1036,"McCarthy et al, 2004",2,W04-0837,0,0,"Association for Computational Linguistics for the Semantic Analysis of Text, Barcelona, Spain, July 2004 SENSEVAL-3: Third International Workshop on the Evaluation of Systems PoS precision recall baseline Noun 95 73 45 Verb 79 43 22 Adjective 88 59 44 Adverb 91 72 59 All PoS 90 63 41Table 2: The SENSEVAL-2 first sense on the SEN SEVAL-2 English all-words data system can be tuned to a given genre or domain (McCarthy et al, 2004) and also because there will be words that occur with insufficient frequency inthe hand-tagged resources available","[3, 175, 17]","['Whilst there are a few hand-tagged corpora available for some languages, one would expect the frequency distribution of the senses of words, particularly topical words, to depend on the genre and domain of the text under consideration.', 'We are currently investigating the performance of the first sense heuristic, and this method, for other PoS on SENSEVAL-3 data (McCarthy et al., 2004), although not yet with rankings from domain specific corpora.', 'There are words where the first sense in WordNet is counter-intuitive, because of the size of the corpus, and because where the frequency data does not indicate a first sense, the ordering is arbitrary.']",Method_Citation
2,P04-1036,"McCarthy et al, 2004",3,W04-0837,0,0,"The method is described in (McCarthy et al, 2004), which we summarise here","[29, 73, 106]","['We discuss our method in the following section.', 'This is not ideal since we expect that the sense frequency distributions within SemCor will differ from those in the BNC, from which we obtain our thesaurus.', 'We do not assume that the predominant sense is a method of WSD in itself.']",Method_Citation
3,P04-1036,"McCarthy et al, 2004",5,I08-2105,0,0,"McCarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in WSD.We build upon this previous research, and pro pose an unsupervised WSD method in which senses for two grammatically related words in the sentence will be connected through directed edges","[165, 41, 164]","['Lapata and Brew obtain their priors for verb classes directly from subcategorisation evidence in a parsed corpus, whereas we use parsed data to find distributionally similar words (nearest neighbours) to the target word which reflect the different senses of the word and have associated distributional similarity scores which can be used for ranking the senses according to prevalence.', 'In this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.', 'They used syntactic evidence to find a prior distribution for verb classes, based on (Levin, 1993), and incorporate this in a WSD system.']",Method_Citation
4,P04-1036,"McCarthy et al, 2004",6,I08-2105,0,0,"Previous re search in inducing sense rankings from an untagged corpus (McCarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (Erk, 2007) will provide the starting point for research in this direction","[56, 9, 116]","['For each noun we considered the co-occurring verbs in the direct object and subject relation, the modifying nouns in noun-noun relations and the modifying adjectives in adjective-noun relations.', 'This is shown by the results of the English all-words task in SENSEVAL-2 (Cotton et al., 1998) in figure 1 below, where the first sense is that listed in WordNet for the PoS given by the Penn TreeBank (Palmer et al., 2001).', 'The performance of the predominant sense provided in the SENSEVAL-2 test data provides an upper bound for this task.']",Method_Citation
5,P04-1036,2004,7,I08-2105,0,0,"McCarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the Senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus","[21, 153, 156]","['We believe that an automatic means of finding a predominant sense would be useful for systems that use it as a means of backing-off (Wilks and Stevenson, 1998; Hoste et al., 2001) and for systems that use it in lexical acquisition (McCarthy, 1997; Merlo and Leybold, 2001; Korhonen, 2002) because of the limited size of hand-tagged resources.', 'Most research in WSD concentrates on using contextual features, typically neighbouring words, to help determine the correct sense of a target word.', 'Buitelaar and Sacaleanu (2001) have previously explored ranking and selection of synsets in GermaNet for specific domains using the words in a given synset, and those related by hyponymy, and a term relevance measure taken from information retrieval.']",Method_Citation
6,P04-1036,"McCarthy et al, 2004",8,P06-1012,0,0,"Research by (McCarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn","[128, 71, 1]","['The Reuters corpus (Rose et al., 2002) is a collection of about 810,000 Reuters, English Language News stories.', 'This is transformed from a distance measure in the WN-Similarity package by taking the reciprocal:', 'word sense disambiguation the heuristic of choosing the most common sense is extremely powerful because the distribution of the senses of a word is often skewed.']",Method_Citation
7,P04-1036,"McCarthy et al, 2004",9,P06-1012,0,0,"In addition, we implemented the unsupervised method of (McCarthy et al, 2004), which cal cu lates a prevalence score for each sense of a word to predict the predominant sense","[48, 45, 41]","['To find the first sense of a word ( ) we take each sense in turn and obtain a score reflecting the prevalence which is used for ranking.', 'In order to find the predominant sense of a target word we use a thesaurus acquired from automatically parsed text based on the method of Lin (1998).', 'In this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.']",Method_Citation
8,P04-1036,2004,11,P10-1155,0,0,"McCarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the Wordnet Similarityjcn measure (Jiang and Conrath, 1997)","[70, 30, 53]","['Jiang and Conrath specify a distance measure: , where the third class ( ) is the most informative, or most specific, superordinate synset of the two senses and .', 'Sections 3 and 4 concern experiments using predominant senses from the BNC evaluated against the data in SemCor and the SENSEVAL-2 English all-words task respectively.', 'This weight is the WordNet similarity score ( ) between the target sense ( ) and the sense of ( ) that maximises this score, divided by the sum of all such WordNet similarity scores for and .']",Method_Citation
9,P04-1036,2004,12,W12-3401,0,0,"In doing so, we provide first results on the application to French parsing of WordNet automatic sense ranking (ASR), using the method of McCarthy et al (2004)","[63, 31, 68]","['We experimented using six of these to provide the in equation 1 above and obtained results well over our baseline, but because of space limitations give results for the two which perform the best.', 'In section 5 we present results of the method on two domain specific sections of the Reuters corpus for a sample of words.', 'We are of course able to apply the method to other versions of WordNet. synset, is incremented with the frequency counts from the corpus of all words belonging to that synset, directly or via the hyponymy relation.']",Method_Citation
10,P04-1036,2004,13,W12-3401,0,0,"To define an appropriate categorical distribution over synsets for each 2 lemma x in our source vocabulary, we first use the WordNet resource to identify the set Sx of different senses of x. We then use a distributional thesaurus to perform ASR, which determines the prevalence with respect to x of each sense s? Sx, following the approach of McCarthy et al (2004)","[68, 39, 146]","['We are of course able to apply the method to other versions of WordNet. synset, is incremented with the frequency counts from the corpus of all words belonging to that synset, directly or via the hyponymy relation.', 'We expect that the quantity and similarity of the neighbours pertaining to different senses will reflect the dominance of the sense to which they pertain.', 'Moreover, the chosen senses of the word tie proved to be a textbook example of the behaviour we expected.']",Method_Citation
11,P04-1036,2004,14,W12-3401,0,0,"As explained in Section 2.2, ASR is performed using the method of McCarthy et al (2004)","[9, 28, 128]","['This is shown by the results of the English all-words task in SENSEVAL-2 (Cotton et al., 1998) in figure 1 below, where the first sense is that listed in WordNet for the PoS given by the Penn TreeBank (Palmer et al., 2001).', 'The paper is structured as follows.', 'The Reuters corpus (Rose et al., 2002) is a collection of about 810,000 Reuters, English Language News stories.']",Method_Citation
12,P04-1036,"McCarthy et al, 2004",16,S12-1097,0,0,"This approach is commonly used as a baseline for word sense disambiguation (McCarthy et al, 2004)","[8, 15, 48]","['The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.', 'Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a strong case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to the genre or domain at hand.', 'To find the first sense of a word ( ) we take each sense in turn and obtain a score reflecting the prevalence which is used for ranking.']",Method_Citation
13,P04-1036,"McCarthy et al, 2004",17,W10-2803,0,0,"More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al, 2004), or to work directly with para phrases (McCarthy and Navigli, 2009)","[22, 92, 182]","['More importantly, when working within a specific domain one would wish to tune the first sense heuristic to the domain at hand.', 'For example, in WordNet the first listed sense ofpipe is tobacco pipe, and this is ranked joint first according to the Brown files in SemCor with the second sense tube made of metal or plastic used to carry water, oil or gas etc....', 'In many cases the sense ranking provided in SemCor differs to that obtained automatically because we used the BNC to produce our thesaurus.']",Method_Citation
14,P04-1036,2004,18,W08-2107,0,0,"In addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by Word net resulting in a reasonable WSD heuristic (which is compatible with the results by McCarthy et al (2004))","[1, 81, 38]","['word sense disambiguation the heuristic of choosing the most common sense is extremely powerful because the distribution of the senses of a word is often skewed.', '4 We calculate the accuracy of finding the predominant sense, when there is indeed one sense with a higher frequency than the others for this word in SemCor ( ).', 'For example, the neighbours of star in a dependency-based thesaurus provided by Lin 1 has the ordered list of neighbours: superstar, player, teammate, actor early in the list, but one can also see words that are related to another sense of star e.g. galaxy, sun, world and planet further down the list.']",Method_Citation
15,P04-1036,"McCarthy et al, 2004",19,D07-1026,0,0,"It is worthwhile to remark here that, being the IBLE algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for WSD (McCarthy et al, 2004)","[86, 9, 28]","['The random baseline for ( ) is 24%.', 'This is shown by the results of the English all-words task in SENSEVAL-2 (Cotton et al., 1998) in figure 1 below, where the first sense is that listed in WordNet for the PoS given by the Penn TreeBank (Palmer et al., 2001).', 'The paper is structured as follows.']",Method_Citation
16,P04-1036,"McCarthy et al, 2004",20,W12-2429,0,0,"The first, most frequent sense (MFS) (McCarthy et al, 2004), is widely used baseline for supervised WSD systems","[86, 8, 84]","['The random baseline for ( ) is 24%.', 'The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.', 'The random baseline for choosing the predominant sense over all these words ( ) is 32%.']",Method_Citation
