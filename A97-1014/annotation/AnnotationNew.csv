,Reference Article,Citation Marker,Citance Number,Citing Article,Citation Marker Offset,Citation Offset,Citation Text,Reference Offset,Reference Textt,Discourse Facet
0,A97-1014,"Skut et al, 1997",1,E99-1016,0,0,"This type of model is used to facilitate the syntactic annotation of the NEGRA corpus of German newspaper texts (Skut et al, 1997)","[156, 173, 157]","['Accuracy of the unreliable 10% of assignments is 75%, i.e., the annotator has to alter the choice in 1 of 4 cases when asked for confirmation.', 'This work is part of the DFG Sonderforschungsbereich 378 Rcsource-Adaptim Cogniiivc Proccsses, We wish to thank Tania Avgustinova, Berthold Crysmann, Lars Konieczny, Stephan Oepen, Karel Oliva., Christian Weil3 and two anonymous reviewers for their helpful comments on the content of this paper.', 'Overall accuracy of the tagger is 95%.']",Method_Citation
1,A97-1014,"Skut et al, 1997",2,E99-1016,0,0,"For our experiments, we use the NEGRA corpus (Skut et al, 1997)","[140, 151, 127]","['For the implementation, we used Tcl/Tk Version 4.1.', 'For evaluation, the already annotated sentences were divided into two disjoint sets, one for training (90% of the corpus), the other one for testing (10%).', 'As the need for certain functionalities becomes obvious with growing annotation experience, we have decided to implement the tool in two stages.']",Method_Citation
2,A97-1014,"Skut et al, 1997",3,E12-1047,0,0,"As data we use version 2 of the Negra (Skut et al1997) tree bank, with the common training ,devel 1 10 100 1000 10000 100000 3 4 5 6 7 8 9 Frequenc y Parsing complexity head-driven optimal head-driven Figure 6: The distribution of parsing complexity among productions in Markovized, head-driven grammars read off from NEGRA-25","[142, 145, 156]","['The degree of automation increases with the amount of data available.', 'This amount of data suffices as training material to reliably assign the grammatical functions if the user determines the elements of a phrase and its type (step 1 of the list above).', 'Accuracy of the unreliable 10% of assignments is 75%, i.e., the annotator has to alter the choice in 1 of 4 cases when asked for confirmation.']",Method_Citation
3,A97-1014,1997,5,I05-6010,0,0,According to Skut et al (1997) tree banks have to meet the following requirements: 1,"[158, 15, 163]","['Owing to the partial automation, the average annotation efficiency improves by 25% (from around 4 minutes to 3 minutes per sentence).', 'Existing treebank annotation schemes exhibit a fairly uniform architecture, as they all have to meet the same basic requirements, namely: Descriptivity: Grammatical phenomena are to be described rather than explained.', 'In general, the resulting interpreted data also are closer to semantic annotation and more neutral with respect to particular syntactic theories.']",Method_Citation
4,A97-1014,"Skut et al, 1997",7,C10-1061,0,0,"In contrast, some other tree banks, such as the German NeGra and TIGER tree banks allow annotation with crossing branches (Skut et al, 1997) .Non-local dependencies can then be expressed directly by grouping all dependent elements under a single node","[160, 168, 111]","['These differences can be illustrated by a comparison with the Penn Treebank annotation scheme.', 'We will closely coordinate the further development of our corpus with the annotation work in Verbmobil and with other German efforts in corpus annotation.', 'If the scope of such a word does not directly correspond to a tree node, the word is attached to the lowest node dominating all subconstituents appearing in its scope.']",Method_Citation
5,A97-1014,"Skut et al, 1997",8,C10-1061,0,0,"Our data source is the German NeGra tree bank (Skut et al, 1997)","[150, 64, 25]","['To keep the human annotator from missing errors made by the tagger, we additionally calculate the strongest competitor for each label G. If its probability is close to the winner (closeness is defined by a threshold on the quotient), the assignment is regarded as unreliable, and the annotator is asked to confirm the assignment.', ""The subject is itself a sentence in which the copula (zA) does occur and is assigned the tag HD'."", 'The underlying argument SirlteilITC is not represented directly, but can be recovered from the tree and trace-filler annotations.']",Method_Citation
6,A97-1014,"Skut et al, 1997",9,P05-1039,0,0,"The parsing models we present are trained and tested on the NEGRA corpus (Skut et al, 1997), a hand parsed corpus of German newspaper text containing approximately 20,000 sentences","[3, 161, 74]","['The resulting scheme reflects a stratificational notion of language, and makes only minimal assumpabout the interrelation of the particu- â€¢lar representational strata.', 'The following features of our formalism are then of particular importance: The current tagset comprises only 16 node labels and 34 function tags, yet a. finely grinned classification will take place in the near future.', 'During the first phase, the focus is on annotating correct structures and a coarse-grained classification of grammatical functions, which represent the following areas of information: Dependency type: complements are further classified according to features such as category and case: clausal complements (OC), accusative objects (OA), datives (DA), etc.']",Method_Citation
7,A97-1014,"Skut et al, 1997",10,P03-1013,0,0,"The present paper addresses this question by proposing a probabilistic parsing model trained on Negra (Skut et al, 1997), a syntactically annotated corpus for German","[63, 4, 79]","[""(2) schade, daB kein Arzt anwesend ist, der pity that no doctor present is who sich a.uskennt is competent 'Pity that no competent doctor is here' Note that the root node does not have a head descendant (HD) as the sentence is a predicative construction consisting of a subject (SB) and a predicate (PD) without a copula."", ""The work reported in this paper aims at providing syntactically annotated corpora (treebanks') for stochastic grammar induction."", 'PM stands for morphological particle, a label for German infinitival Z7t and superlative am.']",Method_Citation
8,A97-1014,"Skut et al, 1997",11,P03-1013,0,0,"The annotation scheme (Skut et al, 1997) is modeled to a certain extent on that of the Penn Treebank (Marcuset al, 1993), with crucial differences","[160, 84, 111]","['These differences can be illustrated by a comparison with the Penn Treebank annotation scheme.', 'Consider (qui verbs where the subject of the infinitival VP is not realised syntactically, but co-referent with the subject or object. of the matrix equi verb: (3) er bat mich zu kommen he asked me to come (mich is the understood subject. of kommt,n).', 'If the scope of such a word does not directly correspond to a tree node, the word is attached to the lowest node dominating all subconstituents appearing in its scope.']",Method_Citation
9,A97-1014,"Skut et al, 1997",13,W04-1505,0,0,"German is con sider ably more in ectional which means that discarding functional information is more harmful, and which explains why the NEGRA an notation has been conceived to be quite at (Skut et al, 1997)","[64, 72, 102]","[""The subject is itself a sentence in which the copula (zA) does occur and is assigned the tag HD'."", 'In order to avoid inconsistencies, the corpus is annotated in two stages: basic annotation and nfirtellte714.', ""The difference between the particular NK's lies in the positional and part-of-speech information, which is also sufficient to recover theory-specific structures from our `underspecified' representations.""]",Method_Citation
10,A97-1014,"Skut et al, 1997",14,C04-1074,0,0,"The factors used in the algorithms and the algorithms themselves are evaluated on a Germancorpus annotated with syntactic and co reference in formation (Negra) (Skut et al, 1997)","[137, 129, 128]","['The following commands are available: The three tagsets used by the annotation tool (for words, phrases, and edges) are variable and are stored together with the corpus.', 'In the second phase, secondary links and additional structural functions are supported.', 'In the first phase, the main functionality for building and displaying unordered trees is supplied.']",Method_Citation
11,A97-1014,"Skut et al, 1997",16,P11-2067,0,0,"CKK uses the Dubey and Keller (2003) parser, which is trained on the Negra corpus (Skut et al, 1997)","[64, 150, 115]","[""The subject is itself a sentence in which the copula (zA) does occur and is assigned the tag HD'."", 'To keep the human annotator from missing errors made by the tagger, we additionally calculate the strongest competitor for each label G. If its probability is close to the winner (closeness is defined by a threshold on the quotient), the assignment is regarded as unreliable, and the annotator is asked to confirm the assignment.', ""3 shows the representation of the sentence: (6) sic wurde von preuBischen Truppen besetzt she was by Prussian troops occupied und 1887 dem preuliischen Staat angegliedert and 1887 to-the Prussian state incorporated 'it was occupied by Prussian troops and incorporated into Prussia in 1887' The category of the coordination is labeled CVP here, where C stands for coordination, and VP for the actual category.""]",Method_Citation
12,A97-1014,"Skut et al, 1997",17,W08-1007,0,0,"Earlier studies by Dubey and Keller (2003) and Dubey (2005) using the Negratreebank (Skut et al, 1997) reports that lexicaliza tion of PCFGs decrease the parsing accuracy when parsing Negra? s flat constituent structures","[115, 71, 122]","[""3 shows the representation of the sentence: (6) sic wurde von preuBischen Truppen besetzt she was by Prussian troops occupied und 1887 dem preuliischen Staat angegliedert and 1887 to-the Prussian state incorporated 'it was occupied by Prussian troops and incorporated into Prussia in 1887' The category of the coordination is labeled CVP here, where C stands for coordination, and VP for the actual category."", 'However, there is a trade-off between the granularity of information encoded in the labels and the speed and accuracy of annotation.', 'The tool supports immediate graphical feedback and automatic error checking.']",Method_Citation
13,A97-1014,"Skut et al, 1997",19,D07-1066,0,0,"A comparison of unlexicalised PCFG parsing (Ku ?bler, 2005) trained and evaluated on the German NEGRA (Skut et al, 1997) and the Tu? Ba D/Z (Telljohann et al, 2004) tree banks using LoPar (Schmid, 2000) shows a difference in parsing results of about 16%, using the PARSEVAL metric (Black et al, 1991)","[71, 120, 3]","['However, there is a trade-off between the granularity of information encoded in the labels and the speed and accuracy of annotation.', 'The development of linguistically interpreted corpora presents a laborious and time-consuming task.', 'The resulting scheme reflects a stratificational notion of language, and makes only minimal assumpabout the interrelation of the particu- â€¢lar representational strata.']",Method_Citation
