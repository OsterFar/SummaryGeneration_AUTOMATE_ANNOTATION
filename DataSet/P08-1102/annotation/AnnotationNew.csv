,Reference Article,Citation Marker,Citance Number,Citing Article,Citation Marker Offset,Citation Offset,Citation Text,Reference Offset,Reference Textt,Discourse Facet
0,P08-1102,2008,1,C08-1049,0,0,"Following Jiang et al (2008), we describe segmentation and Joint S& amp; T as below: For a given Chinese sentence appearing as a character sequence: C 1: n= C 1 C 2.",[9],"To segment and tag a character sequence, there are two strategies to choose: performing POS tagging following segmentation; or joint segmentation and POS tagging (Joint S&T).",Method_Citation
1,P08-1102,2008,2,C08-1049,0,0,"As described in Ng and Low (2004 )andJiang et al (2008), we use s indicating a single character word, while b, m and e indicating the be gin, middle and end of a word respectively",[25],"According to Ng and Low (2004), the segmentation task can be transformed to a tagging problem by assigning each character a boundary tag of the following four types: We can extract segmentation result by splitting the labelled result into subsequences of pattern s or bm*e which denote single-character word and multicharacter word respectively.",Method_Citation
2,P08-1102,2008,3,C08-1049,0,0,plates called lexical-target in the column below areintroduced by Jiang et al (2008),[139],"The authors were supported by National Natural Science Foundation of China, Contracts 60736014 and 60573188, and 863 State Key Project No.",Method_Citation
3,P08-1102,2008,4,P12-1110,0,0,"For CTB-5, we refer to the split by Duan et al (2007) as CTB-5d, and to the split by Jiang et al (2008) as CTB-5j",[139],"The authors were supported by National Natural Science Foundation of China, Contracts 60736014 and 60573188, and 863 State Key Project No.",Method_Citation
4,P08-1102,2008,5,D12-1126,0,0,Jiang et al (2008) proposes a cascaded linear model for joint Chinese word segmentation and POS tagging,[1],We propose a cascaded linear model for joint Chinese word segmentation and partof-speech tagging.,Method_Citation
5,P08-1102,2008,6,C10-1135,0,0,"We use the feature templates the same as Jiang et al, (2008) to extract features form E model",[122],Another important feature is the labelling model.,Method_Citation
6,P08-1102,"Jiangetal., 2008a",8,P12-1025,0,0,"approach, where basic processing units are characters which compose words (Jiangetal., 2008a)",[86],"Line 4 scans words of all possible lengths l (l = 1.. min(i, K), where i points to the current considering character).",Method_Citation
7,P08-1102,2008b,9,C10-2096,0,0,"The solid lines show the 1-best result, which is wrong. Jiang et al (2008b) stress the problems in re ranking phase",[137],We will investigate these problems in the following work.,Method_Citation
8,P08-1102,"Jiang et al, 2008a",10,C10-2096,0,0,"6.1.1 Baseline Forest-based System We first segment the Chinese sentences into the1-best segmentations using a state-of-the-art system (Jiang et al, 2008a), since it is not necessary for a conventional parser to take as input the POS tagging results",[24],It is a better idea to perform segmentation and POS tagging jointly in a uniform framework.,Method_Citation
9,P08-1102,"Jiang et al, 2008a",11,C10-2096,0,0,"6.1.2 Lattice-forest SystemWe first segment and POS tag the Chinese sentences into word lattices using the same system (Jiang et al, 2008a), and prune each lattice into a reasonable size using the marginal probability-based pruning algorithm",[23],We can see that segmentation and POS tagging task is to divide a character sequence into several subsequences and label each of them a POS tag.,Method_Citation
10,P08-1102,"Jiang et al, 2008",12,C10-1132,0,0,"However, when we repeat the work of (Jiang et al, 2008), which reports to achieve the state-of-art performance in the data-sets that we adopt, it has been found that some features (e.g., C0) are unnoticeably trained several times in their model (which are implicitly generated from different feature templates used in the paper)",[52],"However, such features are generated dynamically during the decoding procedure so that the feature space enlarges much more rapidly.",Method_Citation
11,P08-1102,"Jiang et al, 2008",13,C10-1132,0,0,"Unicode/CP936 1.1M/55K 104K/13K 0.035 Table 3: Corpus statistics for the second SIGHAN Bakeoff appears twice, which is generated from two different templates Cn (with n=0, generates C0) and [C0Cn] (used in (Jiang et al, 2008), with n=0, generates [C0C0])",[91],"The first was conducted to test the performance of the perceptron on segmentation on the corpus from SIGHAN Bakeoff 2, including the Academia Sinica Corpus (AS), the Hong Kong City University Corpus (CityU), the Peking University Corpus (PKU) and the Microsoft Research Corpus (MSR).",Method_Citation
12,P08-1102,"Jiang et al, 2008",14,C10-1132,0,0,"As all the features adopted in (Jiang et al, 2008) possess binary values, if a binary feature is repeated n times, then it should behave like a real-valued feature with its value to be? n?, at least in principle",[53],Figure 2 shows the growing tendency of feature space with the introduction of these features as well as the character-based ones.,Method_Citation
13,P08-1102,"Jiang et al, 2008",15,C10-1132,0,0,"Inspired by (Jiang et al, 2008), we set the real d Although Table 5 has shown that the proposed all the value of C0 to be 2.0, the value of C-1C0anC0C1 to be 3.0, and the values of all other features to be 1.0 for the character-based discriminative-plus model",[116],"In order to inspect how much improvement each feature brings into the cascaded model, every time we removed a feature while retaining others, then retrained the model and tested its performance on the test set.",Method_Citation
14,P08-1102,"Jiang et al, 2008",17,C10-1132,0,0,"Last, (Jiang et al, 2008) 5 adds repeated features implicitly based on (Ng and Low, 2004)",[53],Figure 2 shows the growing tendency of feature space with the introduction of these features as well as the character-based ones.,Method_Citation
15,P08-1102,Jiang et al2008a,20,D12-1046,0,0,"Previous joint models mainly focus on word segmentation and POS tagging task, such as the virtual nodes method (Qian et al2010), cascaded linear model (Jiang et al2008a) ,perceptron (Zhang and Clark, 2008), sub-word based stacked learning (Sun, 2011), re ranking (Jiang et al2008b)",[1],We propose a cascaded linear model for joint Chinese word segmentation and partof-speech tagging.,Method_Citation
