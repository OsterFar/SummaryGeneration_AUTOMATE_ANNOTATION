,Reference Article,Citation Marker,Citance Number,Citing Article,Citation Marker Offset,Citation Offset,Citation Text,Reference Offset,Reference Textt,Discourse Facet
0,P08-1028,2008,1,D08-1094,0,0,"Mitchell and Lapata (2008) propose a framework to represent the meaning of the combination p+ a as a function f operating on four components: c= f (p, a, R, K) (3) R is the relation holding between p and a, and Kadditional knowledge",[1],This paper proposes a framework for representing the meaning of phrases and sentences in vector space.,Method_Citation
1,P08-1028,2008,4,P14-1060,0,0,"While works such asthe SDSM model suffer from the problem of sparsity in composing structures beyond bi grams and trigrams, methods such as Mitchell and Lapata (2008) and (Socher et al, 2012) and Grefenstetteand Sadrzadeh (2011) are restricted by significant model biases in representing semantic com position by generic algebraic operations",[97],Moreover by using a minimal structure we factor out inessential degrees of freedom and are able to assess the merits of different models on an equal footing.,Method_Citation
2,P08-1028,2008,6,P10-1097,0,0,"Mitchell and Lapata (2008), henceforth M& amp; L, propose a general framework in which meaning representations for complex expressions are computed compositionally by combining the vector representations of the individual words of the complex expression",[44],"For example, assuming that individual words are represented by vectors, we can compute the meaning of a sentence by taking their mean (Foltz et al., 1998; Landauer and Dumais, 1997).",Method_Citation
3,P08-1028,2008,7,P10-1097,0,0,"Interestingly, Mitchell and Lapata (2008) came to the same result in a different setting",[15],Sentences (1-a) and (1-b) contain exactly the same set of words but their meaning is entirely different.,Method_Citation
4,P08-1028,2008,8,D11-1094,0,0,"And Mitchell and Lapata (2008) propose a model for vector composition, focusing on the different functions that might be used to combine the constituent vectors",[38],The projection is defined in terms of circular convolution a mathematical function that compresses the tensor product of two vectors.,Method_Citation
5,P08-1028,2008,9,W11-0131,0,0,"Mitchell and Lapata (2008) provide a general framework for semantic vector composition: p= f (u, v, R, K) (1) 295 where u and v are the vectors to be composed, R is syntactic context, K is a semantic knowledge base, and p is a resulting composed vector (or tensor)",[69],Simply adding the vectors u and v lumps their contents together rather than allowing the content of one vector to pick out the relevant content of the other.,Method_Citation
6,P08-1028,2008,10,W11-0131,0,0,"As Mitchell and Lapata (2008) did, let us temporarily suspend discussion on what semantics populate our vectors for now",[69],Simply adding the vectors u and v lumps their contents together rather than allowing the content of one vector to pick out the relevant content of the other.,Method_Citation
7,P08-1028,2008,11,P13-2083,0,0,"Mitchell and Lapata (2008) propose a framework to define the composition c= f (a, b, r, K) where r is the relation between a and b, and K is the additional knowledge used to define composition",[57],"Let p denote the composition of two vectors u and v, representing a pair of constituents which stand in some syntactic relation R. Let K stand for any additional knowledge or information which is needed to construct the semantics of their composition.",Method_Citation
8,P08-1028,"Mitchell and Lapata, 2008",12,P13-2083,0,0,"As our final set of baselines, we extend two simple techniques proposed by (Mitchell and Lapata, 2008) that use element-wise addition and multiplication operators to perform composition",[51],"Our work proposes a framework for vector composition which allows the derivation of different types of models and licenses two fundamental composition operations, multiplication and addition (and their combination).",Method_Citation
9,P08-1028,2008,13,P10-1021,0,0,"Althoughthis model has been shown to successfully simulate single and multiple-word priming (McDonald and Brew 2004), it failed to predict processing costs in the Embra eye-tracking corpus (McDonald and Shillcock 2003) .In this work we model semantic constraint using the representational framework put forward in Mitchell and Lapata (2008)",[52],"Under this framework, we introduce novel composition models which we compare empirically against previous work using a rigorous evaluation methodology.",Method_Citation
10,P08-1028,2008,14,P10-1021,0,0,"Assuming that h is a linear function of the Cartesian product of u and v allows to specify additive models which are by far the most common method of vector combination in the literature: hi =ui+ vi (3) Alternatively, we can assume that h is a linear function of the tensor product of u and v, and thus derive models based on multiplication: hi =ui? vi (4) Mitchell and Lapata (2008) show that several additive and multiplicative models can be formulated under this framework, including the well known tensor products (Smolensky 1990) and circular convolution (Plate 1995)",[64],"Now, if we assume that p lies in the same space as u and v, avoiding the issues of dimensionality associated with tensor products, and that f is a linear function, for simplicity, of the cartesian product of u and v, then we generate a class of additive models: where A and B are matrices which determine the contributions made by u and v to the product p. In contrast, if we assume that f is a linear function of the tensor product of u and v, then we obtain multiplicative models: where C is a tensor of rank 3, which projects the tensor product of u and v onto the space of p. Further constraints can be introduced to reduce the free parameters in these models.",Method_Citation
11,P08-1028,2008,15,W11-0115,0,0,"Mitchell and Lapata (2008) introduce a whole family of models of compositionality based on vector addition and point wise-multiplication (and a weighted combination of both), evaluated on a sentence similarity task inspired by Kintsch (2001)",[88],We evaluated the models presented in Section 3 on a sentence similarity task initially proposed by Kintsch (2001).,Method_Citation
12,P08-1028,2008,16,W11-0115,0,0,"The approach proposed by Guevara (2010) is really only an extension of the full additive model of Mitchell and Lapata (2008), the only difference being that adopting a supervised learning methodology ensures that the weight parameters in the function are estimated optimally by linear regression",[65],"So, if we assume that only the ith components of u and v contribute to the ith component of p, that these components are not dependent on i, and that the function is symmetric with regard to the interchange of u and v, we obtain a simpler instantiation of an additive model: Analogously, under the same assumptions, we obtain the following simpler multiplicative model: only the ith components of u and v contribute to the ith component of p. Another class of models can be derived by relaxing this constraint.",Method_Citation
13,P08-1028,2008,17,W11-0115,0,0,"For example, Mitchell and Lapata (2008) use their models to approximate the human ratings in their sentence similarity dataset",[132],We also measured how well humans agree in their ratings.,Method_Citation
14,P08-1028,2008,18,W11-1310,0,0,We use other WSM settings following Mitchell and Lapata (2008),[34],Smolensky (1990) proposed the use of tensor products as a means of binding one vector to another.,Method_Citation
15,P08-1028,2008,19,W11-1310,0,0,Mitchell and Lapata (2008) observed that a simple multiplication function modelled compositionality better than addition,[38],The projection is defined in terms of circular convolution a mathematical function that compresses the tensor product of two vectors.,Method_Citation
16,P08-1028,"Mitchell and Lapata, 2008",20,W11-1310,0,0,"We use the compositionality functions, simple addition and simple multiplication to build compositional vectors Vwr1+wr2 and Vwr1 ?wr2. These are as described in (Mitchell and Lapata, 2008)",[45],Vector addition does not increase the dimensionality of the resulting vector.,Method_Citation
