,Reference Article,Citation Marker,Citance Number,Citing Article,Citation Marker Offset,Citation Offset,Citation Text,Reference Offset,Reference Textt,Discourse Facet
0,W06-2932,"McDonald et al, 2006",2,W06-2920,,0.0,"Introduce through post-processing ,e.g. through reattachment rules (Bick, 2006) or if the change increases overall parse tree probability (McDonald et al, 2006)","[21, 3, 57]","['That work extends the maximum spanning tree dependency parsing framework (McDonald et al., 2005a; McDonald et al., 2005b) to incorporate features over multiple edges in the dependency graph.', 'The second stage takes the output from the first and labels all the edges in the dependency graph with appropriate syntactic categories using a globally trained sequence classifier over components of the graph.', 'Performance is measured through unlabeled accuracy, which is the percentage of words that modify the correct head in the dependency graph, and labeled accuracy, which is the percentage of words that modify the correct head and label the dependency edge correctly in the graph.']",Method_Citation
1,W06-2932,2006,3,W06-2920,0.0,0.0,Table 5 shows the official results for submitted parser outputs.31 The two participant groups with the highest total score are McDonald et al (2006) and Nivre et al (2006),"[66, 13, 21]","['These results report the average labeled and unlabeled precision for the 10 languages with the smallest training sets.', 'We evaluate this parser on a diverse set of 13 languages using data provided by the CoNLL-X shared-task organizers (Buchholz et al., 2006; Hajiˇc et al., 2004; Simov et al., 2005; Simov and Osenova, 2003; Chen et al., 2003; B¨ohmov´a et al., 2003; Kromann, 2003; van der Beek et al., 2002; Brants et al., 2002; Kawata and Bartels, 2000; Afonso et al., 2002; Dˇzeroski et al., 2006; Civit Torruella and MartiAntonin, 2002; Nilsson et al., 2005; Oflazer et al., 2003; Atalay et al., 2003).', 'That work extends the maximum spanning tree dependency parsing framework (McDonald et al., 2005a; McDonald et al., 2005b) to incorporate features over multiple edges in the dependency graph.']",Method_Citation
2,W06-2932,2006,4,W06-2920,0.0,0.0,"Even though McDonald et al (2006) and Nivre et al (2006) obtained very similar overall scores, a more detailed look at their performance shows clear differences","[13, 104, 11]","['We evaluate this parser on a diverse set of 13 languages using data provided by the CoNLL-X shared-task organizers (Buchholz et al., 2006; Hajiˇc et al., 2004; Simov et al., 2005; Simov and Osenova, 2003; Chen et al., 2003; B¨ohmov´a et al., 2003; Kromann, 2003; van der Beek et al., 2002; Brants et al., 2002; Kawata and Bartels, 2000; Afonso et al., 2002; Dˇzeroski et al., 2006; Civit Torruella and MartiAntonin, 2002; Nilsson et al., 2005; Oflazer et al., 2003; Atalay et al., 2003).', 'We have presented results showing that the spanning tree dependency parsing framework of McDonald et al. (McDonald et al., 2005b; McDonald and Pereira, 2006) generalizes well to languages other than English.', 'This has been shown through their successful use in many standard natural language processing tasks, including machine translation (Ding and Palmer, 2005), sentence compression (McDonald, 2006), and textual inference (Haghighi et al., 2005).']",Method_Citation
3,W06-2932,2006,5,W08-1007,0.0,0.0,"The high est score on parsing German in the CoNLL-X shared task was obtained by the system of McDonald et al (2006) with a LAS of 87.34 based on the TIGER tree bank, but we want to stress that these results are not comparable due to different data sets (anda different policy regarding the inclusion of punctuation) .The constituency versions were evaluated according to the labeled recall (LR), labeled precision (LP) and labeled F-score (LF)","[14, 6, 49]","['The results are promising and show the language independence of our system under the assumption of a labeled dependency corpus in the target language.', 'With the availability of resources such as the Penn WSJ Treebank, much of the focus in the parsing community had been on producing syntactic representations based on phrase-structure.', 'Is this the first dependent to the left/right of the head?']",Method_Citation
4,W06-2932,2006,6,W09-1210,0.0,,McDonald et al (2006) use an additional algorithm,"[13, 104, 21]","['We evaluate this parser on a diverse set of 13 languages using data provided by the CoNLL-X shared-task organizers (Buchholz et al., 2006; Hajiˇc et al., 2004; Simov et al., 2005; Simov and Osenova, 2003; Chen et al., 2003; B¨ohmov´a et al., 2003; Kromann, 2003; van der Beek et al., 2002; Brants et al., 2002; Kawata and Bartels, 2000; Afonso et al., 2002; Dˇzeroski et al., 2006; Civit Torruella and MartiAntonin, 2002; Nilsson et al., 2005; Oflazer et al., 2003; Atalay et al., 2003).', 'We have presented results showing that the spanning tree dependency parsing framework of McDonald et al. (McDonald et al., 2005b; McDonald and Pereira, 2006) generalizes well to languages other than English.', 'That work extends the maximum spanning tree dependency parsing framework (McDonald et al., 2005a; McDonald et al., 2005b) to incorporate features over multiple edges in the dependency graph.']",Method_Citation
5,W06-2932,"McDonald et al, 2006",7,W12-3407,0.0,0.0,"Regarding the data-driven parsers, we have made use of MaltParser (Nivre et al, 2007b) and MST Parser (McDonald et al, 2006), two state of the art dependency parsers representing two dominant approaches in data-driven dependency parsing, and that have been successfully applied to typologically different languages and tree banks (McDonald and Nivre, 2007)","[8, 104, 44]","['This interest has generally come about due to the computationally efficient and flexible nature of dependency graphs and their ability to easily model non-projectivity in freer-word order languages.', 'We have presented results showing that the spanning tree dependency parsing framework of McDonald et al. (McDonald et al., 2005b; McDonald and Pereira, 2006) generalizes well to languages other than English.', 'We use the MIRA online learner to set the weights (Crammer and Singer, 2003; McDonald et al., 2005a) since we found it trained quickly and provide good performance.']",Method_Citation
6,W06-2932,"McDonald et al, 2006",8,I08-1012,0.0,0.0,"In fact, our approach can also be applied to other parsers, such as (Yamada and Matsumoto, 2003)? s parser, (McDonald et al., 2006)? s parser, and so on","[11, 71, 8]","['This has been shown through their successful use in many standard natural language processing tasks, including machine translation (Ding and Palmer, 2005), sentence compression (McDonald, 2006), and textual inference (Haghighi et al., 2005).', 'Including rich morphology features naturally helped with highly inflected languages, in particular Spanish, Arabic, Turkish, Slovene and to a lesser extent Dutch and Portuguese.', 'This interest has generally come about due to the computationally efficient and flexible nature of dependency graphs and their ability to easily model non-projectivity in freer-word order languages.']",Method_Citation
7,W06-2932,"McDonald et al, 2006",11,N07-1050,0.0,0.0,"We have shown that, for languages with a7McDonald et al (2006) use post-processing for non projective dependencies and for labeling","[79, 53, 54]","['Although overall unlabeled accuracy is 86%, most verbs and some conjunctions attach to their head words with much lower accuracy: 69% for main verbs, 75% for the verb ser, and 65% for coordinating conjunctions.', 'We trained models for all 13 languages provided by the CoNLL organizers (Buchholz et al., 2006).', 'Based on performance from a held-out section of the training data, we used non-projective parsing algorithms for Czech, Danish, Dutch, German, Japanese, Portuguese and Slovene, and projective parsing algorithms for Arabic, Bulgarian, Chinese, Spanish, Swedish and Turkish.']",Method_Citation
8,W06-2932,"McDonald et al, 2006",12,D07-1122,0.0,0.0,"As described in (McDonald et al, 2006), we treat the labeling of dependencies as a sequence labeling problem","[41, 36, 29]","['To model this we treat the labeling of the edges (i, j1), ... , (i, jM) as a sequence labeling problem, We use a first-order Markov factorization of the score s(l(i,jm), l(i,jm�1), i, y, x) in which each factor is the score of labeling the adjacent edges (i, jm) and (i, jm−1) in the tree y.', 'However, in a two stage system we can incorporate features over the entire output of the unlabeled parser since that structure is fixed as input.', 'We then add to the representation of the edge: Mi as head features, Mj as dependent features, and also each conjunction of a feature from both sets.']",Method_Citation
9,W06-2932,2006,14,D07-1015,0.0,0.0,5It should be noted that McDonald et al (2006) use a richer feature set that is incomparable to our features,"[90, 21, 104]","['We need to look more carefully at verb features that may be useful here, in particular features that distinguish finite and non-finite forms.', 'That work extends the maximum spanning tree dependency parsing framework (McDonald et al., 2005a; McDonald et al., 2005b) to incorporate features over multiple edges in the dependency graph.', 'We have presented results showing that the spanning tree dependency parsing framework of McDonald et al. (McDonald et al., 2005b; McDonald and Pereira, 2006) generalizes well to languages other than English.']",Method_Citation
10,W06-2932,2006,18,D10-1004,0.0,0.0,"Entries marked with? are the highest reported in the literature, to the best of our knowledge, beating (sometimes slightly) McDonald et al (2006), Martins et al (2008), Martins et al (2009), and, in the case of English Proj., also the third-order parser of Koo and Collins (2010), which achieves 93.04% on that dataset (their experiments in Czech are not comparable, since the datasets are different)","[14, 92, 6]","['The results are promising and show the language independence of our system under the assumption of a labeled dependency corpus in the target language.', 'For example, in the test sentence Lo que decia Mae West de si misma podriamos decirlo tambi´en los hombres:..., decia’s head is given as decirlo, although the main verbs of relative clauses are normally dependent on what the relative modifies, in this case the article Lo.', 'With the availability of resources such as the Penn WSJ Treebank, much of the focus in the parsing community had been on producing syntactic representations based on phrase-structure.']",Method_Citation
11,W06-2932,"McDonald et al, 2006",19,P08-1108,0.0,0.0,"The specific graph-based model studied in this work is that presented by McDonald et al (2006), which factors scores over pairs of arcs (instead of just single arcs) and uses near exhaustive search for unlabeled parsing coupled with a separate classifier to label each arc. We call this system MSTParser, or simply MST for short, which is also the name of the freely available implementation.2 2.3 Transition-Based Models","[25, 57, 41]","['For instance, the system of McDonald et al. (2005a) incorporates features over the part of speech of words occurring between and around a possible head-dependent relation.', 'Performance is measured through unlabeled accuracy, which is the percentage of words that modify the correct head in the dependency graph, and labeled accuracy, which is the percentage of words that modify the correct head and label the dependency edge correctly in the graph.', 'To model this we treat the labeling of the edges (i, j1), ... , (i, jM) as a sequence labeling problem, We use a first-order Markov factorization of the score s(l(i,jm), l(i,jm�1), i, y, x) in which each factor is the score of labeling the adjacent edges (i, jm) and (i, jm−1) in the tree y.']",Method_Citation
12,W06-2932,"McDonald et al, 2006",20,P08-1108,0.0,0.0,"More precisely, dependency arcs (or pairs of arcs) are first represented by a high dimensional feature vector f (i, j, l)? Rk, where f is typically a bi nary feature vector over properties of the arc as well as the surrounding input (McDonald et al, 2005a; McDonald et al, 2006)","[25, 29, 62]","['For instance, the system of McDonald et al. (2005a) incorporates features over the part of speech of words occurring between and around a possible head-dependent relation.', 'We then add to the representation of the edge: Mi as head features, Mj as dependent features, and also each conjunction of a feature from both sets.', 'For the remainder of the paper we provide a general error analysis across a wide set of languages plus a detailed error analysis of Spanish and Arabic.']",Method_Citation
